# 交付Dubbo微服务到K8s

* Dubbo是什么
  * SOA服务化治理方案的核心框架
  * 是一个分布式服务架构，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案
  * 简单说，dubbo就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有dubbo这样的分布式服务框架的需求，并且本质上是个服务调用的框架，就是个远程服务调用的分布式框架
* Dubbo能做什么
  * 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入
  * 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点
  * 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者
* 架构
  * Provider：暴露服务的服务提供方
  * Consumer：调用远程服务的服务消费方
  * Registry：服务注册与发现的注册中心
  * Monitor：统计服务的调用次数和调用时间的监控中心
  * Container：服务运行容器（载体）

![image-20200817233003931](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200817233003931.png)

![image-20200817233236959](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200817233236959.png)

![image-20200817233818944](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200817233818944.png)

* Zookeeper是Dubbo微服务集群的注册中心
* 它的高可用机制和K8S的etcd集群一致
* 由Java编写，所以需要jdk环境

## 安装jdk

```shell
# 安装jdk8
https://blog.stanley.wang/2019/01/18/%E5%AE%9E%E9%AA%8C%E6%96%87%E6%A1%A32%EF%BC%9A%E5%AE%9E%E6%88%98%E4%BA%A4%E4%BB%98%E4%B8%80%E5%A5%97dubbo%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0kubernetes%E9%9B%86%E7%BE%A4/
```

```shell
# 所有机器
[root@hdss7-11 src]# ls -l|grep jdk
-rw-r--r-- 1 root root 153530841 Jan 17 17:49 jdk-8u201-linux-x64.tar.gz
[root@hdss7-11 src]# mkdir /usr/java
[root@hdss7-11 src]# tar xf jdk-8u201-linux-x64.tar.gz -C /usr/java
[root@hdss7-11 src]# ln -s /usr/java/jdk1.8.0_201 /usr/java/jdk
[root@hdss7-11 src]# vi /etc/profile
export JAVA_HOME=/usr/java/jdk
export PATH=$JAVA_HOME/bin:$JAVA_HOME/bin:$PATH
export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar
```

## 安装zk

```shell
scp /Volumes/woody-2/Big_Data/oldboy_k8s/day3/day3软件包/zookeeper-3.4.14.tar.gz root@192.168.0.11:/data
# 7-11、7-12、7-21
[root@hdss7-11 data]# tar -zxvf zookeeper-3.4.14.tar.gz -C /opt
[root@hdss7-11 data]# ln -s /opt/zookeeper-3.4.14/ /opt/zookeeper
[root@hdss7-11 data]# mkdir -pv /data/zookeeper/data /data/zookeeper/logs
[root@hdss7-11 data]# vi /opt/zookeeper/conf/zoo.cfg
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/data/zookeeper/data
dataLogDir=/data/zookeeper/logs
clientPort=2181
server.1=zk1.od.com:2888:3888
server.2=zk2.od.com:2888:3888
server.3=zk3.od.com:2888:3888

[root@hdss7-11 data]# vi /data/zookeeper/data/myid
1
[root@hdss7-12 data]# vi /data/zookeeper/data/myid
2
[root@hdss7-21 data]# vi /data/zookeeper/data/myid
3
```

```shell
# dns解析
## 7-11
[root@hdss7-11 bin]# vi /var/named/od.com.zone
zk1	 A 192.168.0.11
zk2	 A 192.168.0.12
zk3	 A 192.168.0.21
[root@hdss7-11 bin]# systemctl restart named
# 验证解析
[root@hdss7-11 bin]# dig -t A zk1.od.com @192.168.0.11 +short
192.168.0.11
```

```shell
# 7-11、7-12、7-21 
[root@hdss7-11 data]# /opt/zookeeper/bin/zkServer.sh start
[root@hdss7-11 data]# netstat -luntp|grep 2181
tcp6       0      0 :::2181                 :::*                    LISTEN      6226/java
[root@hdss7-12 data]# /opt/zookeeper/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Mode: leader
```

## 部署jenkins

* 制作Jenkins的Docker镜像
  * 设置了容器启动时使用的用户为root
  * 设置容器内的时区为UTC+8
  * 加入了ssh私钥（拉取git代码的两种方式：基于http和基于ssh）
  * 加入登陆harbor的config文件
  * 修改了ssh客户端的配置
  * 安装了一个docker客户端
* 配置共享存储NFS
* 交付Jenkins到K8S集群
* 配置CI流水线

* 准备镜像

  ```shell
  # 7-200
  [root@hdss7-200 ~]# docker pull jenkins/jenkins:2.190.3
  [root@hdss7-200 ~]# docker images | grep jenkins
  jenkins/jenkins                    2.190.3             22b8b9a84dbe        9 months ago        568MB
  [root@hdss7-200 ~]# docker tag 22b8b9a84dbe harbor.od.com/public/jenkins:v2.190.3
  [root@hdss7-200 ~]# docker push harbor.od.com/public/jenkins:v2.190.3
  ```

* 自定义Dockerfile

  ```shell
  # 生成ssh密钥对
  [root@hdss7-200 ~]# ssh-keygen -t rsa -b 2048 -C "1093520060@qq.com" -N "" -f /root/.ssh/id_rsa
  
  # 在运维主机HDSS7-200.host.com上编辑自定义dockerfile
  [root@hdss7-200 harbor]# mkdir -p /data/dockerfile/jenkins
  [root@hdss7-200 harbor]# cd /data/dockerfile/jenkins
  [root@hdss7-200 harbor]# vi /data/dockerfile/jenkins/Dockerfile
  
  FROM harbor.od.com/public/jenkins:v2.190.3
  USER root
  RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &&\ 
      echo 'Asia/Shanghai' >/etc/timezone
  ADD id_rsa /root/.ssh/id_rsa
  ADD config.json /root/.docker/config.json     # 登陆远程仓库的信息
  ADD get-docker.sh /get-docker.sh              # 装docker客户端
  RUN echo "    StrictHostKeyChecking no" >> /etc/ssh/sshd_config &&\
      /get-docker.sh
   
  # 可以试下后面加 --mirror Aliyun 
  # RUN echo "    StrictHostKeyChecking no" >> /etc/ssh/sshd_config &&\
  #    /get-docker.sh --mirror Aliyun  
  
  [root@hdss7-200 jenkins]# cp /root/.docker/config.json .
  [root@hdss7-200 jenkins]# curl -fsSL get.docker.com -o get-docker.sh
  [root@hdss7-200 jenkins]# chmod +x get-docker.sh
  # 7-200创建harbor私有仓库infra
  [root@hdss7-200 jenkins]# docker build . -t harbor.od.com/infra/jenkins:v2.190.3
  ------------------------------------------------------------------------------------------------------------
  # 当镜像一直build失败时使用提供的jenkins-with_getdocker_v2.190.3.tar导入到docker中，然后打个tag
  [root@hdss7-200 data]# docker load < jenkins-with_getdocker_v2.190.3.tar
  bcefb321da47: Loading layer  5.632kB/5.632kB
  9fc8db2f121d: Loading layer  14.85kB/14.85kB
  643250c0a147: Loading layer  404.5MB/404.5MB
  Loaded image ID: sha256:0a3393cb519aa7a43a6fe9999cac54d7ae995b4c2b81578f4d9129cd658302f3
  [root@hdss7-200 data]# docker images
  <none>         <none>              0a3393cb519a        8 months ago        972MB     0a3393cb519a
  [root@hdss7-200 data]# docker inspect 0a3393cb519a
  [root@hdss7-200 data]# docker tag 0a3393cb519a harbor.od.com/infra/jenkins:v2.190.3
  # 重复使用导入的镜像
  # 更改Dockerfile，使用自己的配置文件 
  FROM harbor.od.com/infra/jenkins:v2.190.3
  USER root
  RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &&\
      echo 'Asia/Shanghai' >/etc/timezone
  ADD id_rsa /root/.ssh/id_rsa
  ADD config.json /root/.docker/config.json
  ADD get-docker.sh /get-docker.sh
  [root@hdss7-200 jenkins]# docker build . -t harbor.od.com/infra/jenkins:v2.190.3_11
  [root@hdss7-200 jenkins]# docker push harbor.od.com/infra/jenkins:v2.190.3_11
  # 老师的版本的Dockerfile
  FROM harbor.od.com/public/jenkins:v2.190.3
  USER root
  RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &&\ 
      echo 'Asia/Shanghai' >/etc/timezone
  ADD id_rsa /root/.ssh/id_rsa
  ADD config.json /root/.docker/config.json
  RUN echo "    StrictHostKeyChecking no" >> /etc/ssh/sshd_config &&\
      /get-docker.sh
  ------------------------------------------------------------------------------------------------------------
  # [root@hdss7-200 jenkins]# docker push harbor.od.com/infra/jenkins:v2.190.3
  [root@hdss7-200 ~]# cat /root/.ssh/id_rsa.pub
  ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCrPHZoO4OLhwVG1eOwvj5y9JVJm57CsdF81Ybp55hsy7DZhjxIRcM8qhTTCpJc15hLxJBB81UpwYfQUhY3U0auUnlqbCKqhFOvWZEXGnF4E2Ch5N/CXeOGbt+SXm6J54NQ1BJkWCh+U9Guff7et431JrfDzl5kaXh9D+3EzL5ov8UJb2+8B3slaGg7MpiIQRQ5/aUS/pkfkD0538pa/KfRuiShk2gnbDENjDgxocBoCnTQsyethp08G8IOztaKzG32kayy1YDktFdWEc8tW7AT/BxuABPlaxYLq+hytkiswhoWerWNW7gRKuOm/qWoigTlbwcRexhK+z8DGQ0BPntJ 1093520060@qq.com
  # id_rsa.pub添加到gitee的设置-安全设置-SSH公钥中
  [root@hdss7-200 jenkins]# docker run --rm harbor.od.com/infra/jenkins:v2.190.3_11 ssh -i /root/.ssh/id_rsa -T git@gitee.com
  Warning: Permanently added 'gitee.com,180.97.125.228' (ECDSA) to the list of known hosts.
  Hi dyjwoody! You've successfully authenticated, but GITEE.COM does not provide shell access
  ```
  
  ![image-20200818223828746](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200818223828746.png)
  
```shell
  # 创建namespace
[root@hdss7-22 ~]# kubectl create namespace infra
namespace/infra created
[root@hdss7-21 data]# kubectl create secret docker-registry harbor --docker-server=harbor.od.com --docker-username=admin --docker-password=Harbor12345 -n infra
secret/harbor created
```

  ![image-20200818224659162](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200818224659162.png)

* 准备共享存储

  ```shell
  # 运维主机和所有的运算节点（所有运算节点只需instll即可）
  [root@hdss7-200 jenkins]# yum install nfs-utils -y
  
  # 这些只在运维主机
  [root@hdss7-200 jenkins]# vi /etc/exports
  	/data/nfs-volume 192.168.0.0/24(rw,no_root_squash)
  [root@hdss7-200 jenkins]# mkdir /data/nfs-volume
  [root@hdss7-200 jenkins]# systemctl start nfs
  [root@hdss7-200 jenkins]# systemctl enable nfs
  [root@hdss7-200 jenkins]# cd /data/k8s-yaml/
  [root@hdss7-200 k8s-yaml]# mkdir jenkins
  [root@hdss7-200 k8s-yaml]# cd jenkins/
  [root@hdss7-200 jenkins]# vim dp.yaml
  kind: Deployment
  apiVersion: extensions/v1beta1
  metadata:
    name: jenkins
    namespace: infra
    labels:
      name: jenkins
  spec:
    replicas: 1
    selector:
      matchLabels:
        name: jenkins
    template:
      metadata:
        labels:
          app: jenkins
          name: jenkins
      spec:
        volumes:
        - name: data
          nfs:
            server: hdss7-200
            path: /data/nfs-volume/jenkins_home
        - name: docker
          hostPath:
            path: /run/docker.sock
            type: ''
        containers:
        - name: jenkins
          image: harbor.od.com/infra/jenkins:v2.190.3_11
          ports:
          - containerPort: 8080
            protocol: TCP
          env:
          - name: JAVA_OPTS
            value: -Xmx512m -Xms512m
          volumeMounts:
          - name: data
            mountPath: /var/jenkins_home
          - name: docker
            mountPath: /run/docker.sock
        imagePullSecrets:
        - name: harbor
        securityContext:
          runAsUser: 0
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 1
        maxSurge: 1
    revisionHistoryLimit: 7
    progressDeadlineSeconds: 600
  
  [root@hdss7-200 jenkins]# vi svc.yaml
  kind: Service
  apiVersion: v1
  metadata: 
    name: jenkins
    namespace: infra
  spec:
    ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
    selector:
      app: jenkins
  
  [root@hdss7-200 jenkins]# vi ingress.yaml
  
  kind: Ingress
  apiVersion: extensions/v1beta1
  metadata: 
    name: jenkins
    namespace: infra
  spec:
    rules:
    - host: jenkins.od.com
      http:
        paths:
        - path: /
          backend: 
            serviceName: jenkins
            servicePort: 80
  
  [root@hdss7-200 jenkins]# mkdir /data/nfs-volume/jenkins_home
  [root@hdss7-21 data]# file /run/docker.sock
  /run/docker.sock: socket
  [root@hdss7-21 data]# kubectl apply -f http://k8s-yaml.od.com/jenkins/dp.yaml
  deployment.extensions/jenkins created
  [root@hdss7-21 data]# kubectl apply -f http://k8s-yaml.od.com/jenkins/svc.yaml
  service/jenkins created
  [root@hdss7-21 data]# kubectl apply -f http://k8s-yaml.od.com/jenkins/ingress.yaml
  ingress.extensions/jenkins created
  [root@hdss7-21 data]# kubectl get all -n infra
  NAME                           READY   STATUS    RESTARTS   AGE
  pod/jenkins-6749f8fcc4-q2kmp   1/1     Running   0          64s
  NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
  service/jenkins   ClusterIP   10.254.183.131   <none>        80/TCP    39s
  NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
  deployment.apps/jenkins   1/1     1            1           64s
  NAME                                 DESIRED   CURRENT   READY   AGE
  replicaset.apps/jenkins-6749f8fcc4   1         1         1       64s
  [root@hdss7-200 jenkins_home]# cd /data/nfs-volume/jenkins_home
  [root@hdss7-200 jenkins_home]# ll
  
  # 7-11上解析域名
  [root@hdss7-11 bin]# vi /var/named/od.com.zone
  	jenkins            A    192.168.0.10
  [root@hdss7-11 bin]# systemctl restart named
  [root@hdss7-11 bin]# dig -t A jenkins.od.com @192.168.0.11 +short
  192.168.0.10
  # 浏览器访问
  http://jenkins.od.com/
  # dashboard页面中查看Jenkins的日志，如果有Jenkins is fully up and running，则说明Jenkins已经起来了
  [root@hdss7-200 jenkins_home]# cat /data/nfs-volume/jenkins_home/secrets/initialAdminPassword
  e538de5a57dc4f858e6d9e5f1a031f74
  # 先不安装插件，后续再安装插件
  # admin
  # admin123
  # Manage Jenkins - Configure Global Security
  ## 勾选 Allow anonymous read access
  ## 去掉勾选  Prevent Cross Site Request Forgery exploits
  # Manage Jenkins - Manage Plugins
  ## 安装Blue Ocean
  ```

    ![image-20200818233634429](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200818233634429.png)

  ![image-20200819200155551](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200819200155551.png)

  * Dashboard（仪表盘）
  * 基于RBAC认证的一个GUI资源管理插件
    * 两个常用版本：v1.8.3和v1.10.1
  * K8S如何基于RBAC进行鉴权
    * 手撕ssl证书签发
  
  * Jenkins安装docker客户端后，Jenkins通过/run/docker.sock可以与Docker服务端引擎通信
  
  * 向k8s中交付应用
    1. 准备docker镜像
    2. docker上传到私有仓库
    3. 资源配置清单：必须包含Pod控制器

## 安装maven

```shell
# 7-200
[root@hdss7-200 harbor]# mkdir /data/nfs-volume/jenkins_home/maven-3.6.1-8u232
[root@hdss7-200 maven-3.6.1-8u232]# tar -zxvf apache-maven-3.6.1-bin.tar.gz -C /data/nfs-volume/jenkins_home/maven-3.6.1-8u232
cd /data/nfs-volume/jenkins_home/maven-3.6.1-8u232
[root@hdss7-200 maven-3.6.1-8u232]# mv apache-maven-3.6.1/* .
# /data/nfs-volume/jenkins_home/ 已经挂载到jenkins镜像里了
[root@hdss7-200 maven-3.6.1-8u232]# vi /data/nfs-volume/jenkins_home/maven-3.6.1-8u232/conf/settings.xml
<mirror>
  <id>alimaven</id>
  <name>aliyun maven</name>
  <url>http://maven.aliyun.com/nexus/content/groups/public/</url>
  <mirrorOf>central</mirrorOf>        
</mirror>
---------------------
# 可以给maven指定版本jdk
1. 解压jdk7到/data/nfs-volume/jenkins_home/
2. 修改vi /data/nfs-volume/jenkins_home/maven-3.6.1-8u232/bin/mvn文件，里面添加JAVA_HOME值为jdk7的路径即可
---------------------
```

## 制作dubbo微服务的底包镜像

```shell
[root@hdss7-200 harbor]# docker pull docker.io/stanleyws/jre8:8u112
[root@hdss7-200 harbor]# docker images | grep jre
stanleyws/jre8                     8u112               fa3a085d6ef1        3 years ago         363MB
[root@hdss7-200 harbor]# docker tag fa3a085d6ef1 harbor.od.com/public/jre:8u112
[root@hdss7-200 harbor]# docker push harbor.od.com/public/jre:8u112
[root@hdss7-200 harbor]# cd /data/dockerfile/
[root@hdss7-200 dockerfile]# mkdir jre8
[root@hdss7-200 dockerfile]# cd jre8/
[root@hdss7-200 jre8]# vi Dockerfile
FROM harbor.od.com/public/jre:8u112
RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &&\
    echo 'Asia/Shanghai' >/etc/timezone
ADD config.yml /opt/prom/config.yml
ADD jmx_javaagent-0.3.1.jar /opt/prom/
WORKDIR /opt/project_dir
ADD entrypoint.sh /entrypoint.sh
CMD ["/entrypoint.sh"]

# 普罗米修斯的配置
[root@hdss7-200 jre8]# vi config.yml 
---
rules:
  - pattern: '.*'

# jmx_prometheus_javaagent 收集jvm信息提供给普罗米修斯
[root@hdss7-200 jre8]# wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.3.1/jmx_prometheus_javaagent-0.3.1.jar -O jmx_javaagent-0.3.1.jar

# 定义环境变量
# 运行时的环境变量，由k8s的资源配置清单传
# 云原生思想
[root@hdss7-200 jre8]# vi entrypoint.sh
#!/bin/sh
M_OPTS="-Duser.timezone=Asia/Shanghai -javaagent:/opt/prom/jmx_javaagent-0.3.1.jar=$(hostname -i):${M_PORT:-"12346"}:/opt/prom/config.yml"                  # hostname -i pod的IP       -"12346" 不传值时的默认值
C_OPTS=${C_OPTS}
JAR_BALL=${JAR_BALL}
exec java -jar ${M_OPTS} ${C_OPTS} ${JAR_BALL}
# exec 后面的内容代替了shell脚本，变成了pid=1的进程，此时springboot程序编程了前台程序pid=1
# 保持docker生命周期在running状态，而不是exit
# 当发现容器一直起不来时，可以试下exec的方式

[root@hdss7-200 jre8]# chmod +x entrypoint.sh
# harbor中创建base公开仓库
[root@hdss7-200 jre8]# docker build . -t harbor.od.com/base/jre8:8u112
[root@hdss7-200 jre8]# docker push harbor.od.com/base/jre8:8u112
```

```shell
# jenkins中配置Pipeline
# new item - dubbo-demo - pipeline
## 勾选 Discard old build - Days to keep builds 3 - Max # of builds to keep 30
## 勾选 This project is parameterized
1. String Parameter
	name:app_name
	Default Value: 不填
	Description:项目的名称，例：dubbo-demo-service
	勾选 Trim the string
2. String Parameter
	name:image_name
	Default Value: 不填
	Description:docker镜像的名称，例：app/dubbo-demo-service
	勾选 Trim the string	
3. String Parameter
	name:git_repo
	Default Value: 不填
	Description:项目所在的git中央仓库的地址，例如：https://gitee.com/stanleywang/dubbo-demo-service.git
	勾选 Trim the string	
4. String Parameter
	name:git_ver
	Default Value: 不填
	Description:项目所在的git中央仓库所对应的，项目的分支或者版本号
	勾选 Trim the string 
5. String Parameter
	name:add_tag
	Default Value: 不填
	Description:docker镜像标签的一部分，日期时间戳，例如：20200820_0833
	勾选 Trim the string 
6. String Parameter
	name:mvn_dir
	Default Value: /
	Description:编译项目的目录，默认为目录的根目录
	勾选 Trim the string    
7. String Parameter
	name:target_dir
	Default Value: ./target
	Description:编译完成项目后，产生的jar/war包所在的目录
	勾选 Trim the string 	
8. String Parameter
	name:mvn_cmd
	Default Value:mvn clean package -Dmaven.test.skip=true
	Description:编译所执行的命令
	勾选 Trim the string 	
9. Choice Parameter
	name:base_image
	Choices: 
					base/jre7:7u80
					base/jre8:8u112
	Description:项目使用的docker底包镜像
10. Choice Parameter
	name:maven
	Choices: 
					3.6.1-8u232
					3.2.5-7u045
					2.2.1-6u025
					base/jre8:8u112
	Description:项目使用的docker底包镜像
```

```shell
# pipeline script

pipeline {
  agent any 
    stages {
      stage('pull') { //get project code from repo 
        steps {
          sh "git clone ${params.git_repo} ${params.app_name}/${env.BUILD_NUMBER} && cd ${params.app_name}/${env.BUILD_NUMBER} && git checkout ${params.git_ver}"
        }
      }
      stage('build') { //exec mvn cmd
        steps {
          sh "cd ${params.app_name}/${env.BUILD_NUMBER}  && /var/jenkins_home/maven-${params.maven}/bin/${params.mvn_cmd}"
        }
      }
      stage('package') { //move jar file into project_dir
        steps {
          sh "cd ${params.app_name}/${env.BUILD_NUMBER} && cd ${params.target_dir} && mkdir project_dir && mv *.jar ./project_dir"
        }
      }
      stage('image') { //build image and push to registry
        steps {
          writeFile file: "${params.app_name}/${env.BUILD_NUMBER}/Dockerfile", text: """FROM harbor.od.com/${params.base_image}
ADD ${params.target_dir}/project_dir /opt/project_dir"""
          sh "cd  ${params.app_name}/${env.BUILD_NUMBER} && docker build -t harbor.od.com/${params.image_name}:${params.git_ver}_${params.add_tag} . && docker push harbor.od.com/${params.image_name}:${params.git_ver}_${params.add_tag}"
        }
      }
    }
}
```

```shell
# harbor中添加app私有仓库

# 选择 Build with Parameters
dubbo-demo-service
app/dubbo-demo-service
https://gitee.com/stanleywang/dubbo-demo-service.git
master
20200821_2124
/
./dubbo-server/target
mvn clean package -Dmaven.test.skip=true
base/jre8:8u112
3.6.1-8u232
```

![image-20200821221707499](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200821221707499.png)

```shell
# jenkins 中因为jar包拉不下来导致执行不成功，多执行几次，大概率是网速太慢导致
# 进行多次还是执行不成功，则删除Jenkins pod 或则重启node服务器
```

```shell
# 资源配置清单
[root@hdss7-200 bin]# cd /data/k8s-yaml/
[root@hdss7-200 k8s-yaml]# mkdir dubbo-demo-service
[root@hdss7-200 k8s-yaml]# cd dubbo-demo-service/

[root@hdss7-22 ~]# kubectl create ns app
[root@hdss7-22 ~]# kubectl create secret docker-registry harbor --docker-server=harbor.od.com --docker-username=admin --docker-password=Harbor12345 -n app

[root@hdss7-200 dubbo-demo-service]# vi dp.yaml
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: dubbo-demo-service
  namespace: app
  labels:
    name: dubbo-demo-service
spec:
  replicas: 1
  selector:
    matchLabels:
      name: dubbo-demo-service
  template:
    metadata:
      labels:
        app: dubbo-demo-service
        name: dubbo-demo-service
    spec:
      containers:
      - name: dubbo-demo-service
        image: harbor.od.com/app/dubbo-demo-service:master_20200821_2124
        ports:
        - containerPort: 20880
          protocol: TCP
        env:
        - name: JAR_BALL
          value: dubbo-server.jar
        imagePullPolicy: IfNotPresent
      imagePullSecrets:
      - name: harbor
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      securityContext:
        runAsUser: 0
      schedulerName: default-scheduler
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  revisionHistoryLimit: 7
  progressDeadlineSeconds: 600
  
# 三台zk要同时运行起来  
[root@hdss7-12 zookeeper]# pwd
/opt/zookeeper
[root@hdss7-12 zookeeper]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Mode: leader  
[root@hdss7-11 zookeeper]# bin/zkCli.sh -server localhost:2181
```

![image-20200821232532805](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200821232532805.png)

```shell
# 交付dubbo服务提供者到k8s
[root@hdss7-21 zookeeper]# kubectl apply -f http://k8s-yaml.od.com/dubbo-demo-service/dp.yaml
```

![image-20200821232746381](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200821232746381.png)

```shell
# 11上 
[root@hdss7-11 ~]# /opt/zookeeper/bin/zkCli.sh -server localhost:2181
[zk: localhost:2181(CONNECTED) 0] ls /
[dubbo, zookeeper]
[zk: localhost:2181(CONNECTED) 1] ls /dubbo
[com.od.dubbotest.api.HelloService]
[zk: localhost:2181(CONNECTED) 2]
```

![image-20200823073744955](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200823073744955.png)

```shell
# 交付dubbo服务monitor到k8s中
[root@hdss7-200 data]# cd -p /opt/src
[root@hdss7-200 opt]# cd /opt/src
[root@hdss7-200 src]# mv /data/dubbo-monitor-master.zip ./
[root@hdss7-200 src]# yum install unzip -y
[root@hdss7-200 src]# unzip dubbo-monitor-master.zip
[root@hdss7-200 conf]# vi /opt/src/dubbo-monitor-master/dubbo-monitor-simple/conf/dubbo_origin.properties
dubbo.container=log4j,spring,registry,jetty
dubbo.application.name=dubbo-monitor
dubbo.application.owner=OldboyEdu
dubbo.registry.address=zookeeper://zk1.od.com:2181?backup=zk2.od.com:2181,zk3.od.com:2181
dubbo.protocol.port=20880
dubbo.jetty.port=8080
dubbo.jetty.directory=/dubbo-monitor-simple/monitor
dubbo.charts.directory=/dubbo-monitor-simple/charts
dubbo.statistics.directory=/dubbo-monitor-simple/monitor/statistics
dubbo.log4j.file=logs/dubbo-monitor-simple.log
dubbo.log4j.level=WARN

[root@hdss7-200 bin]# vi /opt/src/dubbo-monitor-master/dubbo-monitor-simple/bin/start.sh
# 对内存调小 -Xmx128m -Xms128m -Xmn32m -XX:PermSize=16m  
JAVA_MEM_OPTS=" -server -Xmx128m -Xms128m -Xmn32m -XX:PermSize=16m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 "
else
    JAVA_MEM_OPTS=" -server -Xms128m -Xmx128m -XX:PermSize=16m -XX:SurvivorRatio=2 -XX:+UseParallelGC "
# nohup改为exec，并去掉$，并将exec下面的内容都去掉（不会执行了）
exec java $JAVA_OPTS $JAVA_MEM_OPTS $JAVA_DEBUG_OPTS $JAVA_JMX_OPTS -classpath $CONF_DIR:$LIB_JARS com.alibaba.dubbo.container.Main > $STDOUT_FILE 2>&1

[root@hdss7-200 src]# mv dubbo-monitor-master dubbo-monitor
[root@hdss7-200 src]# cp -a dubbo-monitor /data/dockerfile/
[root@hdss7-200 src]# cd /data/dockerfile/dubbo-monitor/
[root@hdss7-200 dubbo-monitor]# docker build . -t harbor.od.com/infra/dubbo-monitor:latest
[root@hdss7-200 dubbo-monitor]# docker push harbor.od.com/infra/dubbo-monitor:latest
# 资源配置清单
[root@hdss7-200 k8s-yaml]# mkdir -p /data/k8s-yaml/dubbo-monitor/
[root@hdss7-200 k8s-yaml]# vi /data/k8s-yaml/dubbo-monitor/deployment.yaml

kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: dubbo-monitor
  namespace: infra
  labels: 
    name: dubbo-monitor
spec:
  replicas: 1
  selector:
    matchLabels: 
      name: dubbo-monitor
  template:
    metadata:
      labels: 
        app: dubbo-monitor
        name: dubbo-monitor
    spec:
      containers:
      - name: dubbo-monitor
        image: harbor.od.com/infra/dubbo-monitor:latest
        ports:
        - containerPort: 8080
          protocol: TCP
        - containerPort: 20880
          protocol: TCP
        imagePullPolicy: IfNotPresent
      imagePullSecrets:
      - name: harbor
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      securityContext: 
        runAsUser: 0
      schedulerName: default-scheduler
  strategy:
    type: RollingUpdate
    rollingUpdate: 
      maxUnavailable: 1
      maxSurge: 1
  revisionHistoryLimit: 7
  progressDeadlineSeconds: 600

[root@hdss7-200 k8s-yaml]# vi /data/k8s-yaml/dubbo-monitor/svc.yaml

kind: Service
apiVersion: v1
metadata: 
  name: dubbo-monitor
  namespace: infra
spec:
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
  selector: 
    app: dubbo-monitor
  
[root@hdss7-200 k8s-yaml]# vi /data/k8s-yaml/dubbo-monitor/ingress.yaml

kind: Ingress
apiVersion: extensions/v1beta1
metadata: 
  name: dubbo-monitor
  namespace: infra
spec:
  rules:
  - host: dubbo-monitor.od.com
    http:
      paths:
      - path: /
        backend: 
          serviceName: dubbo-monitor
          servicePort: 8080
```

```shell
[root@hdss7-21 ~]# kubectl apply -f http://k8s-yaml.od.com/dubbo-monitor/deployment.yaml
[root@hdss7-21 ~]# kubectl apply -f http://k8s-yaml.od.com/dubbo-monitor/svc.yaml
[root@hdss7-21 ~]# kubectl apply -f http://k8s-yaml.od.com/dubbo-monitor/ingress.yaml

# 11上解析DNS
[root@hdss7-11 ~]# vi /var/named/od.com.zone
	dubbo-monitor      A    192.168.0.10
[root@hdss7-11 ~]# systemctl restart named
[root@hdss7-11 ~]# dig -t A dubbo-monitor.od.com @192.168.0.11 +short
192.168.0.10
# 浏览器访问
http://dubbo-monitor.od.com/
```

![image-20200823082907146](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200823082907146.png)

```shell
# 交付dubbo服消费者到k8s中
## jenkins - dubbo-demo - build with parameters
dubbo-demo-consumer
app/dubbo-demo-consumer
https://gitee.com/dyjwoody/dubbo-demo-web.git     #git@gitee.com:stanleywang/dubbo-demo-web.git
master
20200823_0835
./
./dubbo-client/target
# -e -q 有错误就输出
mvn clean package -e -q -Dmaven.test.skip=true
base/jre8:8u112
3.6.1-8u232

# 200上准备资源配置清单
[root@hdss7-200 dubbo-monitor]# mkdir -p  /data/k8s-yaml/dubbo-demo-consumer/
[root@hdss7-200 dubbo-monitor]# vi /data/k8s-yaml/dubbo-demo-consumer/deployment.yaml

kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: dubbo-demo-consumer
  namespace: app
  labels: 
    name: dubbo-demo-consumer
spec:
  replicas: 1
  selector:
    matchLabels: 
      name: dubbo-demo-consumer
  template:
    metadata:
      labels: 
        app: dubbo-demo-consumer
        name: dubbo-demo-consumer
    spec:
      containers:
      - name: dubbo-demo-consumer
        image: harbor.od.com/app/dubbo-demo-consumer:master_20200823_0835
        ports:
        - containerPort: 8080
          protocol: TCP
        - containerPort: 20880
          protocol: TCP
        env:
        - name: JAR_BALL
          value: dubbo-client.jar
        imagePullPolicy: IfNotPresent
      imagePullSecrets:
      - name: harbor
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      securityContext: 
        runAsUser: 0
      schedulerName: default-scheduler
  strategy:
    type: RollingUpdate
    rollingUpdate: 
      maxUnavailable: 1
      maxSurge: 1
  revisionHistoryLimit: 7
  progressDeadlineSeconds: 600
  
[root@hdss7-200 dubbo-monitor]# vi /data/k8s-yaml/dubbo-demo-consumer/svc.yaml

kind: Service
apiVersion: v1
metadata: 
  name: dubbo-demo-consumer
  namespace: app
spec:
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
  selector: 
    app: dubbo-demo-consumer
  
[root@hdss7-200 harbor]# vi /data/k8s-yaml/dubbo-demo-consumer/ingress.yaml

kind: Ingress
apiVersion: extensions/v1beta1
metadata: 
  name: dubbo-demo-consumer
  namespace: app
spec:
  rules:
  - host: demo.od.com
    http:
      paths:
      - path: /
        backend: 
          serviceName: dubbo-demo-consumer
          servicePort: 8080
          
# 11上解析域名
[root@hdss7-11 ~]# vi /var/named/od.com.zone
	demo               A    192.168.0.10
[root@hdss7-11 ~]# systemctl restart named
[root@hdss7-11 ~]# dig -t A demo.od.com @192.168.0.11 +short
192.168.0.10
```

```shell
# 21上 
kubectl apply -f http://k8s-yaml.od.com/dubbo-demo-consumer/deployment.yaml
kubectl apply -f http://k8s-yaml.od.com/dubbo-demo-consumer/svc.yaml
kubectl apply -f http://k8s-yaml.od.com/dubbo-demo-consumer/ingress.yaml
```

![image-20200823114453169](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20200823114453169.png)

```shell
# 浏览器访问
http://demo.od.com/hello?name=woody
```

```shell
# 无状态的service、consumer可扩缩容
```

```shell
# 修改代码并提交到git上
## 重新再Jenkins上构建
## jenkins - dubbo-demo - build with parameters
# 取commitId的前8位作为git_ver的值 e6516904_20200823_1200
## dashboard上修改deployment.yaml中对应镜像值为的harbor上的值
### 浏览器上访问 http://demo.od.com/hello?name=woody
```

```shell
# 回滚 
##  dashboard上修改deployment.yaml中对应镜像值为的harbor上的值 即可
```

## 集群毁灭性测试

* 某个node节点挂了

  * ```shell
    # 先 
    kubectl delete node hdfss-7-21.host.com
    # 11上
    vi /etc/nginx/nginx.conf
    vi /etc/nginx/conf.d/od.com.conf
    # 注释掉挂掉的node
    nginx -s reload
    ```

  * 自愈机制

    * 会自动将服务重启到其他正常node

* 恢复nginx配置

* 重新调度pod到新的node上

  * 删除pod即可









